{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Obtaining dependency information for pymorphy2 from https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl.metadata\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
      "  Obtaining dependency information for dawg-python>=0.7.1 from https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
      "  Obtaining dependency information for pymorphy2-dicts-ru<3.0,>=2.4 from https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting docopt>=0.6 (from pymorphy2)\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Using cached pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Using cached pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13775 sha256=2bc17a0328cd924f675f7ffb3a57a59acec3fa1b15c5d32f1c41e64359cdbfbb\n",
      "  Stored in directory: c:\\users\\elizabeth\\appdata\\local\\pip\\cache\\wheels\\1a\\b0\\8c\\4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Obtaining dependency information for pymystem3 from https://files.pythonhosted.org/packages/00/8c/98b43c5822620458704e187a1666616c1e21a846ede8ffda493aabe11207/pymystem3-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading pymystem3-0.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\elizabeth\\anaconda3\\lib\\site-packages (from pymystem3) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\elizabeth\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elizabeth\\anaconda3\\lib\\site-packages (from requests->pymystem3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\elizabeth\\anaconda3\\lib\\site-packages (from requests->pymystem3) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elizabeth\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2023.7.22)\n",
      "Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Считайте',\n",
       " 'слова',\n",
       " 'из',\n",
       " 'файла',\n",
       " 'litw',\n",
       " 'win',\n",
       " 'txt',\n",
       " 'и',\n",
       " 'запишите',\n",
       " 'их',\n",
       " 'в',\n",
       " 'список',\n",
       " 'words',\n",
       " 'В',\n",
       " 'заданном',\n",
       " 'предложении',\n",
       " 'исправьте',\n",
       " 'все',\n",
       " 'опечатки',\n",
       " 'заменив',\n",
       " 'слова',\n",
       " 'с',\n",
       " 'опечатками',\n",
       " 'на',\n",
       " 'ближайшие',\n",
       " 'в',\n",
       " 'смысле',\n",
       " 'расстояния',\n",
       " 'Левенштейна',\n",
       " 'к',\n",
       " 'ним',\n",
       " 'слова',\n",
       " 'из',\n",
       " 'списка',\n",
       " 'words',\n",
       " 'Считайте',\n",
       " 'что',\n",
       " 'в',\n",
       " 'слове',\n",
       " 'есть',\n",
       " 'опечатка',\n",
       " 'если',\n",
       " 'данное',\n",
       " 'слово',\n",
       " 'не',\n",
       " 'содержится',\n",
       " 'в',\n",
       " 'списке',\n",
       " 'words']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.'\n",
    "\n",
    "\n",
    "def tknz(data):\n",
    "   return re.findall(r'[а-яА-яЁёa-zA-z]+', data)\n",
    "\n",
    "\n",
    "res = tknz(text)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['счита', 'слов', 'из', 'файл', 'litw', 'win', 'txt', 'и', 'запиш', 'их', 'в', 'список', 'words', 'в', 'зада', 'предложен', 'исправьт', 'все', 'опечатк', 'замен', 'слов', 'с', 'опечатк', 'на', 'ближайш', 'в', 'смысл', 'расстоян', 'левенштейн', 'к', 'ним', 'слов', 'из', 'списк', 'words', 'счита', 'что', 'в', 'слов', 'ест', 'опечатк', 'есл', 'дан', 'слов', 'не', 'содерж', 'в', 'списк', 'words']\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")\n",
    "stemmed_words = [stemmer.stem(word) for word in res]\n",
    "\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Считайте',\n",
       " 'слова',\n",
       " 'из',\n",
       " 'файла',\n",
       " 'litw',\n",
       " 'win',\n",
       " 'txt',\n",
       " 'и',\n",
       " 'запишите',\n",
       " 'их',\n",
       " 'в',\n",
       " 'список',\n",
       " 'word',\n",
       " 'В',\n",
       " 'заданном',\n",
       " 'предложении',\n",
       " 'исправьте',\n",
       " 'все',\n",
       " 'опечатки',\n",
       " 'заменив',\n",
       " 'слова',\n",
       " 'с',\n",
       " 'опечатками',\n",
       " 'на',\n",
       " 'ближайшие',\n",
       " 'в',\n",
       " 'смысле',\n",
       " 'расстояния',\n",
       " 'Левенштейна',\n",
       " 'к',\n",
       " 'ним',\n",
       " 'слова',\n",
       " 'из',\n",
       " 'списка',\n",
       " 'word',\n",
       " 'Считайте',\n",
       " 'что',\n",
       " 'в',\n",
       " 'слове',\n",
       " 'есть',\n",
       " 'опечатка',\n",
       " 'если',\n",
       " 'данное',\n",
       " 'слово',\n",
       " 'не',\n",
       " 'содержится',\n",
       " 'в',\n",
       " 'списке',\n",
       " 'word']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "l = [lemmatizer.lemmatize(word) for word in res]\n",
    "\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['считать',\n",
       " ' ',\n",
       " 'слово',\n",
       " ' ',\n",
       " 'из',\n",
       " ' ',\n",
       " 'файл',\n",
       " ' ',\n",
       " 'litw',\n",
       " '-',\n",
       " 'win',\n",
       " '.',\n",
       " 'txt',\n",
       " ' ',\n",
       " 'и',\n",
       " ' ',\n",
       " 'записывать',\n",
       " ' ',\n",
       " 'они',\n",
       " ' ',\n",
       " 'в',\n",
       " ' ',\n",
       " 'список',\n",
       " ' ',\n",
       " 'words',\n",
       " '. ',\n",
       " 'в',\n",
       " ' ',\n",
       " 'заданный',\n",
       " ' ',\n",
       " 'предложение',\n",
       " ' ',\n",
       " 'исправлять',\n",
       " ' ',\n",
       " 'весь',\n",
       " ' ',\n",
       " 'опечатка',\n",
       " ', ',\n",
       " 'заменять',\n",
       " ' ',\n",
       " 'слово',\n",
       " ' ',\n",
       " 'с',\n",
       " ' ',\n",
       " 'опечатка',\n",
       " ' ',\n",
       " 'на',\n",
       " ' ',\n",
       " 'близкий',\n",
       " ' (',\n",
       " 'в',\n",
       " ' ',\n",
       " 'смысл',\n",
       " ' ',\n",
       " 'расстояние',\n",
       " ' ',\n",
       " 'левенштейн',\n",
       " ') ',\n",
       " 'к',\n",
       " ' ',\n",
       " 'они',\n",
       " ' ',\n",
       " 'слово',\n",
       " ' ',\n",
       " 'из',\n",
       " ' ',\n",
       " 'список',\n",
       " ' ',\n",
       " 'words',\n",
       " '. ',\n",
       " 'считать',\n",
       " ', ',\n",
       " 'что',\n",
       " ' ',\n",
       " 'в',\n",
       " ' ',\n",
       " 'слово',\n",
       " ' ',\n",
       " 'быть',\n",
       " ' ',\n",
       " 'опечатка',\n",
       " ', ',\n",
       " 'если',\n",
       " ' ',\n",
       " 'данный',\n",
       " ' ',\n",
       " 'слово',\n",
       " ' ',\n",
       " 'не',\n",
       " ' ',\n",
       " 'содержаться',\n",
       " ' ',\n",
       " 'в',\n",
       " ' ',\n",
       " 'список',\n",
       " ' ',\n",
       " 'words',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mystem().lemmatize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to C:\\Users\\Elizabeth/.local/bin\\mystem.exe from http://download.cdn.yandex.net/mystem/mystem-3.1-win-64bit.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'считать слово из файл litw-win.txt и записывать они в список words. в заданный предложение исправлять весь опечатка, заменять слово с опечатка на близкий (в смысл расстояние левенштейн) к они слово из список words. считать, что в слово быть опечатка, если данный слово не содержаться в список words.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "def lemmatize_sentence(text):\n",
    "    lemmas = Mystem().lemmatize(text)\n",
    "    return \"\".join(lemmas).strip()\n",
    "\n",
    "lemmatize_sentence(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "task1_cv = cv.fit_transform(task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_cv.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d = pd.read_csv('preprocessed_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>these were so go it surprised even me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>my sisterinlaw made these for us at a family g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
       "      <td>this is based on a french recipe but i changed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>zwetschgenkuchen  bavarian plum cake</td>\n",
       "      <td>this is a traditional fresh plum cake thought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>zwiebelkuchen   southwest german onion cake</td>\n",
       "      <td>this is a traditional late summer early fall s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>zydeco soup</td>\n",
       "      <td>this is a delicious soup that i originally fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>cookies by design   cookies on a stick</td>\n",
       "      <td>ive heard of the cookies by design company but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  \\\n",
       "0             george s at the cove  black bean soup   \n",
       "1                healthy for them  yogurt popsicles   \n",
       "2                      i can t believe it s spinach   \n",
       "3                              italian  gut busters   \n",
       "4          love is in the air  beef fondue   sauces   \n",
       "...                                             ...   \n",
       "29995  zurie s holey rustic olive and cheddar bread   \n",
       "29996          zwetschgenkuchen  bavarian plum cake   \n",
       "29997   zwiebelkuchen   southwest german onion cake   \n",
       "29998                                   zydeco soup   \n",
       "29999        cookies by design   cookies on a stick   \n",
       "\n",
       "                               preprocessed_descriptions  \n",
       "0      an original recipe created by chef scott meska...  \n",
       "1      my children and their friends ask for my homem...  \n",
       "2                  these were so go it surprised even me  \n",
       "3      my sisterinlaw made these for us at a family g...  \n",
       "4      i think a fondue is a very romantic casual din...  \n",
       "...                                                  ...  \n",
       "29995  this is based on a french recipe but i changed...  \n",
       "29996  this is a traditional fresh plum cake thought ...  \n",
       "29997  this is a traditional late summer early fall s...  \n",
       "29998  this is a delicious soup that i originally fou...  \n",
       "29999  ive heard of the cookies by design company but...  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word_tokenize(str(i)) for i in p_d['preprocessed_descriptions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for i in p_d['preprocessed_descriptions']:\n",
    "    words += word_tokenize(str(i))\n",
    "    \n",
    "words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32868"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = [[random.choice(list(words)), random.choice(list(words))] for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['unsweetened', 'crop'],\n",
       " ['beleive', 'sipping'],\n",
       " ['plumped', 'multi'],\n",
       " ['4045', 'scalding'],\n",
       " ['sisterinlaw', 'pierced']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unsweetened', 'crop'] 15\n",
      "['beleive', 'sipping'] 12\n",
      "['plumped', 'multi'] 10\n",
      "['4045', 'scalding'] 12\n",
      "['sisterinlaw', 'pierced'] 12\n"
     ]
    }
   ],
   "source": [
    "for i in para:\n",
    "    print(i, edit_distance(i[0], i[1], substitution_cost=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unsweetened', 'crop'] 15\n",
      "['beleive', 'sipping'] 12\n",
      "['plumped', 'multi'] 10\n",
      "['4045', 'scalding'] 12\n",
      "['sisterinlaw', 'pierced'] 12\n"
     ]
    }
   ],
   "source": [
    "for i in para:\n",
    "    print(i, nltk.edit_distance(i[0], i[1], substitution_cost=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Levenstein(word, ww, k):\n",
    "    r = {}\n",
    "    for w in ww:\n",
    "        if w != word:\n",
    "            r[w] = edit_distance(word, w, substitution_cost=2)\n",
    "    srt = sorted(r.items(), key=lambda item: item[1])\n",
    "    r = {k: v for k, v in srt}\n",
    "    return [srt[i][0] for i in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['popsicle', 'potpies', 'piles']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = 'popsicles'\n",
    "\n",
    "Levenstein(W, words, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = [stemmer.stem(i) for i in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = [lemmatizer.lemmatize(i) for i in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sealer</th>\n",
       "      <td>sealer</td>\n",
       "      <td>sealer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226422</th>\n",
       "      <td>226422</td>\n",
       "      <td>226422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>straightforward</th>\n",
       "      <td>straightforward</td>\n",
       "      <td>straightforward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vegetablesyour</th>\n",
       "      <td>vegetablesyour</td>\n",
       "      <td>vegetablesyour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promiscuous</th>\n",
       "      <td>promiscuous</td>\n",
       "      <td>promiscuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greatnieces</th>\n",
       "      <td>greatnieces</td>\n",
       "      <td>greatnieces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>migrants</th>\n",
       "      <td>migrants</td>\n",
       "      <td>migrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pam</th>\n",
       "      <td>pam</td>\n",
       "      <td>pam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connoisseur</th>\n",
       "      <td>connoisseur</td>\n",
       "      <td>connoisseur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quenches</th>\n",
       "      <td>quenches</td>\n",
       "      <td>quenches</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    stemmed_word  normalized_word\n",
       "word                                             \n",
       "sealer                    sealer           sealer\n",
       "226422                    226422           226422\n",
       "straightforward  straightforward  straightforward\n",
       "vegetablesyour    vegetablesyour   vegetablesyour\n",
       "promiscuous          promiscuous      promiscuous\n",
       "...                          ...              ...\n",
       "greatnieces          greatnieces      greatnieces\n",
       "migrants                migrants          migrant\n",
       "pam                          pam              pam\n",
       "connoisseur          connoisseur      connoisseur\n",
       "quenches                quenches         quenches\n",
       "\n",
       "[32868 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'word': words, 'stemmed_word': st, 'normalized_word': nr})\n",
    "df.set_index('word', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Elizabeth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds = []\n",
    "\n",
    "for i in p_d['preprocessed_descriptions']:\n",
    "    wrds += word_tokenize(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stop = [i for i in wrds if i not in en_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4564649471672189"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(wrds) - len(non_stop))/len(wrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frec(lst, k=10):\n",
    "    dct = {}\n",
    "    for i in lst:\n",
    "        dct[i] = dct[i] + 1 if i in dct else 1\n",
    "    dct = {x: dct[x] for x in sorted(dct.keys(), key=lambda ele: dct[ele], reverse=True)}\n",
    "    return list(dct.keys())[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the', 'a', 'and', 'this', 'i', 'to', 'is', 'it', 'of', 'for'],\n",
       " ['recipe',\n",
       "  'make',\n",
       "  'time',\n",
       "  'use',\n",
       "  'great',\n",
       "  'like',\n",
       "  'easy',\n",
       "  'one',\n",
       "  'made',\n",
       "  'good'])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_frec(wrds), count_frec(non_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import (CountVectorizer, TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11055    this is a combination of the best elements of ...\n",
       "12225    this is the recipe ive used for years to make ...\n",
       "26384    mocktails are nonalcoholic drinks this is a gr...\n",
       "16719    use 1 or 2 tablespoons for an authentic madras...\n",
       "7952     i love cranberries and orange together and thi...\n",
       "Name: preprocessed_descriptions, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = p_d.sample(n=5)\n",
    "sample['preprocessed_descriptions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer()\n",
    "\n",
    "samp_tv = tv.fit_transform(sample['preprocessed_descriptions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11571206, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.17277892, 0.        ,\n",
       "        0.17277892, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.17277892, 0.17277892, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.17277892, 0.17277892, 0.        , 0.        ,\n",
       "        0.17277892, 0.17277892, 0.        , 0.        , 0.17277892,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.17277892, 0.17277892, 0.        , 0.17277892,\n",
       "        0.17277892, 0.09734063, 0.        , 0.13939694, 0.13939694,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.17277892, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.17277892, 0.        , 0.        , 0.17277892, 0.41819083,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.17277892, 0.        , 0.        , 0.17277892,\n",
       "        0.        , 0.17277892, 0.        , 0.        , 0.17277892,\n",
       "        0.        , 0.        , 0.17277892, 0.        , 0.        ,\n",
       "        0.27879389, 0.        , 0.09734063, 0.13939694, 0.        ,\n",
       "        0.        , 0.17277892, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.08326582, 0.08326582, 0.08326582, 0.08326582, 0.        ,\n",
       "        0.        , 0.05576409, 0.        , 0.08326582, 0.        ,\n",
       "        0.        , 0.08326582, 0.08326582, 0.        , 0.08326582,\n",
       "        0.        , 0.08326582, 0.16653164, 0.08326582, 0.08326582,\n",
       "        0.        , 0.        , 0.08326582, 0.08326582, 0.08326582,\n",
       "        0.08326582, 0.16653164, 0.08326582, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08326582,\n",
       "        0.        , 0.        , 0.08326582, 0.08326582, 0.        ,\n",
       "        0.08326582, 0.11152818, 0.08326582, 0.08326582, 0.08326582,\n",
       "        0.        , 0.        , 0.        , 0.08326582, 0.        ,\n",
       "        0.        , 0.09382102, 0.16653164, 0.06717834, 0.06717834,\n",
       "        0.08326582, 0.08326582, 0.        , 0.        , 0.08326582,\n",
       "        0.        , 0.08326582, 0.08326582, 0.08326582, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26871335,\n",
       "        0.16653164, 0.08326582, 0.        , 0.        , 0.08326582,\n",
       "        0.        , 0.        , 0.08326582, 0.08326582, 0.        ,\n",
       "        0.13435668, 0.        , 0.08326582, 0.08326582, 0.        ,\n",
       "        0.08326582, 0.        , 0.        , 0.08326582, 0.08326582,\n",
       "        0.40307003, 0.08326582, 0.04691051, 0.06717834, 0.41632909,\n",
       "        0.        , 0.        , 0.08326582, 0.08326582, 0.        ,\n",
       "        0.08326582, 0.08326582, 0.08326582, 0.08326582, 0.08326582,\n",
       "        0.08326582, 0.08326582, 0.08326582, 0.08326582, 0.24979745,\n",
       "        0.08326582],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.31491864,\n",
       "        0.        , 0.        , 0.31491864, 0.        , 0.31491864,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31491864, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.21090468, 0.        , 0.        , 0.        ,\n",
       "        0.31491864, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.17741967, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.31491864,\n",
       "        0.        , 0.31491864, 0.31491864, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.31491864, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.17741967, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3664082 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3664082 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.3664082 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24538784, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3664082 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.3664082 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3664082 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.3664082 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.47121416, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.35180376, 0.        ,\n",
       "        0.35180376, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1982001 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.35180376, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.35180376, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28383306, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1982001 , 0.        , 0.        ,\n",
       "        0.35180376, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa = samp_tv.toarray()\n",
    "sa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.27299176, 0.03454028, 0.        , 0.093111  ],\n",
       "       [0.27299176, 1.        , 0.04849036, 0.02736766, 0.0923047 ],\n",
       "       [0.03454028, 0.04849036, 1.        , 0.05175345, 0.07032919],\n",
       "       [0.        , 0.02736766, 0.05175345, 1.        , 0.        ],\n",
       "       [0.093111  , 0.0923047 , 0.07032919, 0.        , 1.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = samp_tv * samp_tv.T\n",
    "similarity.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_names = sample['name'].to_numpy()\n",
    "\n",
    "distance_cosine = pd.DataFrame({recipe_names[i]: similarity.toarray()[i] for i in range(5)}, index=recipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fish tacos with herb yogurt</th>\n",
       "      <th>golden fried cornbread</th>\n",
       "      <th>sunset cooler  mocktail</th>\n",
       "      <th>madras curry paste</th>\n",
       "      <th>cranberry orange scones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fish tacos with herb yogurt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272992</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>golden fried cornbread</th>\n",
       "      <td>0.272992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048490</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.092305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunset cooler  mocktail</th>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.048490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.070329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>madras curry paste</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cranberry orange scones</th>\n",
       "      <td>0.093111</td>\n",
       "      <td>0.092305</td>\n",
       "      <td>0.070329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             fish tacos with herb yogurt  \\\n",
       "fish tacos with herb yogurt                     1.000000   \n",
       "golden fried cornbread                          0.272992   \n",
       "sunset cooler  mocktail                         0.034540   \n",
       "madras curry paste                              0.000000   \n",
       "cranberry orange scones                         0.093111   \n",
       "\n",
       "                             golden fried cornbread  sunset cooler  mocktail  \\\n",
       "fish tacos with herb yogurt                0.272992                 0.034540   \n",
       "golden fried cornbread                     1.000000                 0.048490   \n",
       "sunset cooler  mocktail                    0.048490                 1.000000   \n",
       "madras curry paste                         0.027368                 0.051753   \n",
       "cranberry orange scones                    0.092305                 0.070329   \n",
       "\n",
       "                             madras curry paste  cranberry orange scones  \n",
       "fish tacos with herb yogurt            0.000000                 0.093111  \n",
       "golden fried cornbread                 0.027368                 0.092305  \n",
       "sunset cooler  mocktail                0.051753                 0.070329  \n",
       "madras curry paste                     1.000000                 0.000000  \n",
       "cranberry orange scones                0.000000                 1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "\n",
    "for i in range(5):\n",
    "    dist = []\n",
    "    for j in range(5):\n",
    "        dist.append(scipy.spatial.distance.cosine(sa[i], sa[j]))\n",
    "    distances.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.72700824, 0.96545972, 1.        , 0.906889  ],\n",
       "       [0.72700824, 0.        , 0.95150964, 0.97263234, 0.9076953 ],\n",
       "       [0.96545972, 0.95150964, 0.        , 0.94824655, 0.92967081],\n",
       "       [1.        , 0.97263234, 0.94824655, 0.        , 1.        ],\n",
       "       [0.906889  , 0.9076953 , 0.92967081, 1.        , 0.        ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = np.array(distances)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fish tacos with herb yogurt</th>\n",
       "      <th>golden fried cornbread</th>\n",
       "      <th>sunset cooler  mocktail</th>\n",
       "      <th>madras curry paste</th>\n",
       "      <th>cranberry orange scones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fish tacos with herb yogurt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272992</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>golden fried cornbread</th>\n",
       "      <td>0.272992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048490</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.092305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunset cooler  mocktail</th>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.048490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.070329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>madras curry paste</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cranberry orange scones</th>\n",
       "      <td>0.093111</td>\n",
       "      <td>0.092305</td>\n",
       "      <td>0.070329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             fish tacos with herb yogurt  \\\n",
       "fish tacos with herb yogurt                     1.000000   \n",
       "golden fried cornbread                          0.272992   \n",
       "sunset cooler  mocktail                         0.034540   \n",
       "madras curry paste                              0.000000   \n",
       "cranberry orange scones                         0.093111   \n",
       "\n",
       "                             golden fried cornbread  sunset cooler  mocktail  \\\n",
       "fish tacos with herb yogurt                0.272992                 0.034540   \n",
       "golden fried cornbread                     1.000000                 0.048490   \n",
       "sunset cooler  mocktail                    0.048490                 1.000000   \n",
       "madras curry paste                         0.027368                 0.051753   \n",
       "cranberry orange scones                    0.092305                 0.070329   \n",
       "\n",
       "                             madras curry paste  cranberry orange scones  \n",
       "fish tacos with herb yogurt            0.000000                 0.093111  \n",
       "golden fried cornbread                 0.027368                 0.092305  \n",
       "sunset cooler  mocktail                0.051753                 0.070329  \n",
       "madras curry paste                     1.000000                 0.000000  \n",
       "cranberry orange scones                0.000000                 1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = pd.DataFrame({recipe_names[i]: 1-distances[i] for i in range(5)}, index=recipe_names)\n",
    "dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем ближе значение косинусного сходства к единице, тем болшее сходство присутствует между текстами. Соттветственно, наиболее похожими рецептами из выборки `sample` являются `'mermaid delights tuna patties burgers'` и `'molasses pound cake'` (сходство достигает $0,209148$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
